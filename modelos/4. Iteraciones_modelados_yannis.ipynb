{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14iIbKitXA80sgYeoDlD-p3xwdrztLQ4h","timestamp":1764850001493},{"file_id":"1w939MLM0vItnVDXjPcQA6-oDSeqBf073","timestamp":1764797407159},{"file_id":"1FLPtKFHr9iaUDKn7h0oTOvW5VOyDiysy","timestamp":1764794773665},{"file_id":"16pAfug0bv3BIfQaFoekRgv05aFIdBAe7","timestamp":1764774632814}],"collapsed_sections":["5L1ZoNAIKkh2","lMNPnCy9LT3B","dz9Jv11cM-F-","Ojh42bcSOFnS","eCwc085PMoI_","VCy7nm3Id7Qx","4Cwe8oa9h0e8","mMRTllHiuKyM"],"authorship_tag":"ABX9TyOJgz8mLP2o4ctSd/pW0WTn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["---\n","\n","\n","## CARGA DE LIBRER√çA Y DATOS\n","\n","---"],"metadata":{"id":"5L1ZoNAIKkh2"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7XZRUejqKj4m","executionInfo":{"status":"ok","timestamp":1764945211822,"user_tz":-60,"elapsed":915,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"8cc5129d-a235-4b76-8e29-a170ee7fd118"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":103,"metadata":{"id":"wcai8MQjJ9vy","executionInfo":{"status":"ok","timestamp":1764945211887,"user_tz":-60,"elapsed":46,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.impute import SimpleImputer\n","from scipy.stats import rankdata\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import f1_score, classification_report\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from scipy.stats import chi2, f_oneway,chi2_contingency\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import KNNImputer\n","from sklearn.preprocessing import FunctionTransformer, RobustScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n","from xgboost import XGBClassifier\n","from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n","from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n","from sklearn.metrics import make_scorer, roc_auc_score\n","from sklearn.utils import shuffle"]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Cupido_IA_project/train.csv')\n","test = pd.read_csv(\"/content/drive/MyDrive/Cupido_IA_project/test.csv\")\n","submission = pd.read_csv(\"/content/drive/MyDrive/Cupido_IA_project/sample_submission.csv\")"],"metadata":{"id":"0EikpVDqKoq_","executionInfo":{"status":"ok","timestamp":1764945211992,"user_tz":-60,"elapsed":96,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## DEFINICI√ìN PREPROCESADO\n","\n","---"],"metadata":{"id":"lMNPnCy9LT3B"}},{"cell_type":"code","source":["cols_to_int = ['age', 'sex', 'cp', 'restecg']\n","\n","rename_dict = {\n","    \"age\": \"edad\",\n","    \"sex\": \"sexo\",\n","    \"cp\": \"tipo_dolor_pecho\",\n","    \"trestbps\": \"tension_en_descanso\",\n","    \"chol\": \"colesterol\",\n","    \"fbs\": \"azucar\",\n","    \"restecg\": \"electro_en_descanso\",\n","    \"thalach\": \"latidos_por_minuto\",\n","    \"exang\": \"dolor_pecho_con_ejercicio\",\n","    \"oldpeak\": \"cambio_linea_corazon_ejercicio\",\n","    \"slope\": \"forma_linea_corazon_ejercicio\",\n","    \"ca\": \"num_venas_grandes\",\n","    \"thal\": \"estado_corazon_thal\"\n","}\n","\n","cols_a_clippear = [\n","    'tension_en_descanso', 'colesterol',\n","    'latidos_por_minuto', 'cambio_linea_corazon_ejercicio'\n","]\n","\n","categorical_cols_to_round = [\n","    'num_venas_grandes', 'estado_corazon_thal', 'sexo',\n","    'tipo_dolor_pecho', 'dolor_pecho_con_ejercicio',\n","    'azucar', 'forma_linea_corazon_ejercicio', 'electro_en_descanso'\n","]"],"metadata":{"id":"kLy152-tLTJC","executionInfo":{"status":"ok","timestamp":1764945212869,"user_tz":-60,"elapsed":18,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","FUNCIONES DE PREPROCESADO\n","\n","---"],"metadata":{"id":"ktZhfHfSMWqF"}},{"cell_type":"code","source":["def limpieza_inicial(df):\n","    \"\"\"\n","    Realiza conversiones de tipos, renombres y limpieza b√°sica de errores (-9).\n","    Se puede aplicar a todo el dataset antes del split.\n","    \"\"\"\n","    df = df.copy()\n","\n","    for col in cols_to_int:\n","        if col in df.columns:\n","            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n","\n","    object_cols = df.select_dtypes(include=['object']).columns\n","    for col in object_cols:\n","        df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","    df = df.rename(columns=rename_dict)\n","    df.replace([-9, -9.0], np.nan, inplace=True)\n","\n","    return df"],"metadata":{"id":"yZYIcR-sMM5l","executionInfo":{"status":"ok","timestamp":1764945212907,"user_tz":-60,"elapsed":24,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["def limpiar_ceros_fisiologicos(X):\n","    X = X.copy()\n","    cols_imposibles_con_cero = ['tension_en_descanso', 'colesterol']\n","    for col in cols_imposibles_con_cero:\n","        if col in X.columns:\n","            X[col] = X[col].replace({0: np.nan, 0.0: np.nan})\n","    return X"],"metadata":{"id":"k6WPY8AxMtgL","executionInfo":{"status":"ok","timestamp":1764945212917,"user_tz":-60,"elapsed":2,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["def clipear_outliers(X):\n","    X = X.copy()\n","    for col in cols_a_clippear:\n","        if col in X.columns:\n","            p1 = X[col].quantile(0.01)\n","            p99 = X[col].quantile(0.99)\n","            X[col] = X[col].clip(lower=p1, upper=p99)\n","    return X"],"metadata":{"id":"BccdJqYGMwz8","executionInfo":{"status":"ok","timestamp":1764945212936,"user_tz":-60,"elapsed":11,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["def crear_flags_mnar(df):\n","    \"\"\"\n","    ACTUALIZADO (Estrategia Pruning):\n","    Solo creamos flag para 'num_venas_grandes'.\n","    'estado_corazon_thal_is_missing' se considera ruido (Grupo 1) y no se genera.\n","    \"\"\"\n","    df_new = df.copy()\n","    # Solo venas, thal is missing se elimina por V=0.040\n","    cols_mnar = ['num_venas_grandes']\n","    for col in cols_mnar:\n","        if col in df_new.columns:\n","            df_new[f'{col}_is_missing'] = df_new[col].isna().astype(int)\n","    return df_new"],"metadata":{"id":"w7g5ipXWM0Uf","executionInfo":{"status":"ok","timestamp":1764945212980,"user_tz":-60,"elapsed":43,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["class RobustKNNImputerWrapper(BaseEstimator, TransformerMixin):\n","    def __init__(self, n_neighbors=5):\n","        self.n_neighbors = n_neighbors\n","        self.scaler = RobustScaler()\n","        self.imputer = KNNImputer(n_neighbors=n_neighbors, weights='distance')\n","        self.feature_names_in_ = None\n","\n","    def fit(self, X, y=None):\n","        self.feature_names_in_ = X.columns if hasattr(X, 'columns') else [f\"feat_{i}\" for i in range(X.shape[1])]\n","        X_scaled = self.scaler.fit_transform(X)\n","        self.imputer.fit(X_scaled)\n","        return self\n","\n","    def transform(self, X):\n","        X_scaled = self.scaler.transform(X)\n","        X_imputed_scaled = self.imputer.transform(X_scaled)\n","        X_imputed = self.scaler.inverse_transform(X_imputed_scaled)\n","        return pd.DataFrame(X_imputed, columns=self.feature_names_in_, index=X.index)\n","\n","    def set_output(self, *, transform=None):\n","        return self"],"metadata":{"id":"tcGtUVuz-Ycf","executionInfo":{"status":"ok","timestamp":1764945212982,"user_tz":-60,"elapsed":1,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["def redondear_imputaciones(X):\n","    X = X.copy()\n","    for col in categorical_cols_to_round:\n","        if col in X.columns:\n","            X[col] = X[col].round()\n","    return X"],"metadata":{"id":"k6FNu_mFJaP0","executionInfo":{"status":"ok","timestamp":1764945212985,"user_tz":-60,"elapsed":1,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["def aplicar_feature_engineering_avanzado(df):\n","    \"\"\"\n","    ACTUALIZADO:\n","    1. Se eliminan c√°lculos innecesarios (rango_colesterol, porcentaje_freq).\n","    2. Se calculan las variables compuestas necesarias antes de borrar las fuentes.\n","    \"\"\"\n","    df = df.copy()\n","\n","    # 1. Flag Depresi√≥n ST (Usada en Score Stress)\n","    if 'cambio_linea_corazon_ejercicio' in df.columns:\n","        df['flag_depresion_st'] = (df['cambio_linea_corazon_ejercicio'] > 0).astype(int)\n","\n","    # 2. Flag Hipertensi√≥n (Absorbe info de tension_en_descanso)\n","    if 'tension_en_descanso' in df.columns:\n","        df['flag_hipertension'] = (df['tension_en_descanso'] > 130).astype(int)\n","\n","    # NOTA: Eliminado calculo de 'porcentaje_frecuencia_max' (Grupo 2 - Redundancia negativa)\n","    # NOTA: Eliminado calculo de 'rango_colesterol' (Grupo 1 - Ruido)\n","\n","    # 3. Score Respuesta al Estr√©s (Driver Tier 1)\n","    if 'dolor_pecho_con_ejercicio' in df.columns and 'flag_depresion_st' in df.columns:\n","        df['score_respuesta_stress'] = df['dolor_pecho_con_ejercicio'] + df['flag_depresion_st']\n","\n","    # 4. Carga de Comorbilidad (Absorbe azucar y electro)\n","    cols_comorbilidad = ['azucar', 'flag_hipertension', 'electro_en_descanso']\n","    if set(cols_comorbilidad).issubset(df.columns):\n","        # Nos aseguramos que electro sea binario para la suma (0 = normal, 1,2 = anormal)\n","        electro_punto = (df['electro_en_descanso'] > 0).astype(int)\n","        df['carga_comorbilidad'] = df['azucar'] + df['flag_hipertension'] + electro_punto\n","\n","    return df"],"metadata":{"id":"1nl8bYKh-fFl","executionInfo":{"status":"ok","timestamp":1764945213011,"user_tz":-60,"elapsed":25,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["def ejecutar_pruning_agresivo(df):\n","    \"\"\"\n","    Elimina las variables de Grupo 1 (Ruido) y Grupo 2 (Redundancia/Absorbidas)\n","    despu√©s de haberlas utilizado para crear las variables compuestas.\n","    \"\"\"\n","    df = df.copy()\n","\n","    vars_a_eliminar = [\n","        # GRUPO 1: Ruido Puro\n","        'electro_en_descanso', # Usado en carga, adios.\n","        'colesterol',          # Inutil en este dataset, adios.\n","        # 'rango_colesterol' y 'thal_missing' ya no se generan.\n","\n","        # GRUPO 2: Redundantes / Absorbidas\n","        'azucar',               # Absorbida en carga, adios.\n","        'tension_en_descanso'   # Absorbida en flag_hipertension, adios.\n","    ]\n","\n","    # Eliminamos solo si existen (para evitar errores)\n","    cols_existentes = [c for c in vars_a_eliminar if c in df.columns]\n","    if cols_existentes:\n","        df = df.drop(columns=cols_existentes)\n","\n","    return df"],"metadata":{"id":"Did4d0XdJmfb","executionInfo":{"status":"ok","timestamp":1764945213044,"user_tz":-60,"elapsed":32,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["def optimizar_k_knn(X_train, k_range=[3, 5, 7, 9, 11, 15]):\n","    # Versi√≥n simplificada de la original\n","    X_temp = limpiar_ceros_fisiologicos(X_train)\n","    X_temp = clipear_outliers(X_temp)\n","    X_complete = X_temp.dropna().copy()\n","    if len(X_complete) < 50: return 5\n","\n","    rmse_scores = {}\n","    scaler = RobustScaler()\n","    X_scaled_array = scaler.fit_transform(X_complete)\n","    np.random.seed(42)\n","    mask = np.random.rand(*X_scaled_array.shape) < 0.1\n","    X_missing_sim = X_scaled_array.copy()\n","    X_missing_sim[mask] = np.nan\n","\n","    for k in k_range:\n","        imputer = KNNImputer(n_neighbors=k, weights='distance')\n","        X_imputed = imputer.fit_transform(X_missing_sim)\n","        error = np.sqrt(mean_squared_error(X_scaled_array[mask], X_imputed[mask]))\n","        rmse_scores[k] = error\n","\n","    return min(rmse_scores, key=rmse_scores.get)"],"metadata":{"id":"AfPbT_3eM9FR","executionInfo":{"status":"ok","timestamp":1764945213047,"user_tz":-60,"elapsed":1,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":["---\n","## APLICACI√ìN DEL FLUJO DE PREPROCESADO DEFINIDO\n","\n","---"],"metadata":{"id":"dz9Jv11cM-F-"}},{"cell_type":"code","source":["df_train = df.copy()\n","df_test = test.copy()\n","\n","df_train = limpieza_inicial(df_train)\n","df_test = limpieza_inicial(df_test)\n","\n","target = \"label\"\n","\n","X_train = df_train.drop(columns=target)\n","y_train = df_train[target]\n","\n","if target in df_test.columns:\n","    X_test = df_test.drop(columns=target)\n","    y_test = df_test[target]\n","else:\n","    X_test = df_test.copy()\n","\n","best_k = optimizar_k_knn(X_train)\n","\n","# 3. Definici√≥n del Pipeline\n","pipeline_feature_engineering = Pipeline([\n","    ('limpieza_ceros', FunctionTransformer(limpiar_ceros_fisiologicos, validate=False)),\n","    ('clipear_outliers', FunctionTransformer(clipear_outliers, validate=False)),\n","    ('mnar_flags', FunctionTransformer(crear_flags_mnar, validate=False)),\n","    ('imputacion_robusta', RobustKNNImputerWrapper(n_neighbors=best_k)),\n","    ('rounding', FunctionTransformer(redondear_imputaciones, validate=False)),\n","    ('feature_engineering', FunctionTransformer(aplicar_feature_engineering_avanzado, validate=False)),\n","    # CAMBIO CLAVE: COMENTAMOS ESTA L√çNEA (No borramos columnas en segundo intento del stacking)\n","    ('pruning_agresivo', FunctionTransformer(ejecutar_pruning_agresivo, validate=False)),\n","    # ---------------------------------------------------------\n","    ('final_scaler', RobustScaler())\n","]).set_output(transform=\"pandas\")"],"metadata":{"id":"FR0YZtJqNFii","executionInfo":{"status":"ok","timestamp":1764945214603,"user_tz":-60,"elapsed":471,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":["---\n","## EJECUCI√ìN Y VERIFICACI√ìN DE TRANSFORMACI√ìN\n","\n","---"],"metadata":{"id":"Ojh42bcSOFnS"}},{"cell_type":"code","source":["print(\"Ajustando pipeline con estrategia de Pruning Agresivo...\")\n","X_train_prep = pipeline_feature_engineering.fit_transform(X_train)\n","y_train_prep = y_train.copy()\n","\n","X_test_prep = pipeline_feature_engineering.transform(X_test)\n","print(\"\\n--- Proceso finalizado ---\")\n","print(f\"Dimensiones Train final: {X_train_prep.shape}\")\n","print(f\"Columnas finales en el dataset: \\n{X_train_prep.columns.tolist()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdCZCR6DOJ-U","executionInfo":{"status":"ok","timestamp":1764945215982,"user_tz":-60,"elapsed":170,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"d04d7032-f81c-4da9-ac7d-3caa3d265048"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["Ajustando pipeline con estrategia de Pruning Agresivo...\n","\n","--- Proceso finalizado ---\n","Dimensiones Train final: (732, 14)\n","Columnas finales en el dataset: \n","['edad', 'sexo', 'tipo_dolor_pecho', 'latidos_por_minuto', 'dolor_pecho_con_ejercicio', 'cambio_linea_corazon_ejercicio', 'forma_linea_corazon_ejercicio', 'num_venas_grandes', 'estado_corazon_thal', 'num_venas_grandes_is_missing', 'flag_depresion_st', 'flag_hipertension', 'score_respuesta_stress', 'carga_comorbilidad']\n"]}]},{"cell_type":"markdown","source":["---\n","## ENTRENAMIENTO Y PREDICCI√ìN SOBRE ENSAMBLES\n","\n","---"],"metadata":{"id":"eCwc085PMoI_"}},{"cell_type":"markdown","source":["---\n","### DEFINICI√ìN MODELOS PREVIO AL STACKING\n","\n","---"],"metadata":{"id":"xRgh7HoVQypE"}},{"cell_type":"code","source":["# 1. Logistic Regression\n","# Params: {'lr__C': 1, 'lr__class_weight': None, 'lr__penalty': 'l2', 'lr__solver': 'lbfgs'}\n","best_lr = LogisticRegression(\n","    C=1,\n","    class_weight=None,\n","    penalty='l2',\n","    solver='lbfgs',\n","    max_iter=1000, # Aumentado por seguridad de convergencia\n","    random_state=42)\n","\n","# 2. Random Forest\n","# Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n","best_rf = RandomForestClassifier(\n","    class_weight='balanced',\n","    max_depth=5,\n","    min_samples_split=5,\n","    n_estimators=100,\n","    random_state=42)\n","\n","# 3. XGBoost\n","# Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0}\n","best_xgb = XGBClassifier(\n","    learning_rate=0.1,\n","    max_depth=5,\n","    n_estimators=100,\n","    subsample=1.0,\n","    use_label_encoder=False,\n","    eval_metric='mlogloss',\n","    random_state=42)\n","\n","# 4. Balanced Random Forest\n","# Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n","best_brf = BalancedRandomForestClassifier(\n","    max_depth=None,\n","    min_samples_split=2,\n","    n_estimators=200,\n","    random_state=42)\n","\n","# 5. Easy Ensemble\n","# Params: {'n_estimators': 10, 'sampling_strategy': 'auto'}\n","best_eec = EasyEnsembleClassifier(\n","    n_estimators=10,\n","    sampling_strategy='auto',\n","    random_state=42)"],"metadata":{"id":"URXMIrpLQsvv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","ENTRENAMIENTO Y PREDICCIONES SOBRE TEST SET\n","\n","---"],"metadata":{"id":"1rero78pT0q5"}},{"cell_type":"code","source":["#0.5489\n","stacking_clf = StackingClassifier(\n","    estimators=[\n","        ('lr', best_lr),\n","        ('rf', best_rf),\n","        ('xgb', best_xgb),\n","        ('brf', best_brf),\n","        ('eec', best_eec)\n","    ],\n","    final_estimator=LogisticRegression(max_iter=1000),\n","    cv=5, # Cross-validation interno para las meta-features\n","    n_jobs=-1)\n","\n","# Entrenamos con los datos PREPROCESADOS\n","stacking_clf.fit(X_train_prep, y_train)\n","\n","# Usamos el modelo ya entrenado arriba\n","y_test_pred = stacking_clf.predict(X_test_prep)\n","\n","# Verificaciones de seguridad\n","print(f\"Predicciones generadas: {len(y_test_pred)}\")\n","print(f\"Filas en sample_submission: {len(submission)}\")\n","\n","if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_stacking_pruned_opt1.csv\", index=False)\n","    print(\"¬°Archivo 'submission_stacking_pruned_opt1.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden. Revisa si se borraron filas en el test.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tqcx6tsCTz8k","executionInfo":{"status":"ok","timestamp":1764851199020,"user_tz":-60,"elapsed":25663,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"e7d84b2f-ae60-4c7c-b846-c6110be97478"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicciones generadas: 184\n","Filas en sample_submission: 184\n","¬°Archivo 'submission_stacking_pruned_opt1.csv' guardado con √©xito!\n","   ID  label\n","0   0      3\n","1   1      0\n","2   2      0\n","3   3      3\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","ENTRENAMIENTO Y PREDICCIONES SOBRE TEST SET SIN PRUNING (sin borrar columnas)\n","\n","---"],"metadata":{"id":"kjqrk5SjWJmJ"}},{"cell_type":"code","source":["stacking_clf = StackingClassifier(\n","    estimators=[\n","        ('lr', best_lr),\n","        ('rf', best_rf),\n","        ('xgb', best_xgb),\n","        ('brf', best_brf),\n","        ('eec', best_eec)\n","    ],\n","    # Cambio: A√±adimos class_weight='balanced' al meta-modelo tambi√©n\n","    final_estimator=LogisticRegression(max_iter=1000, class_weight='balanced'),\n","    cv=5,\n","    n_jobs=-1)\n","\n","# Entrenamos con los datos PREPROCESADOS\n","stacking_clf.fit(X_train_prep, y_train)\n","\n","# Usamos el modelo ya entrenado arriba\n","y_test_pred = stacking_clf.predict(X_test_prep)\n","\n","# Verificaciones de seguridad\n","print(f\"Predicciones generadas: {len(y_test_pred)}\")\n","print(f\"Filas en sample_submission: {len(submission)}\")\n","\n","if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_stacking_opt1.csv\", index=False)\n","    print(\"¬°Archivo 'submission_stacking_opt1.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden. Revisa si se borraron filas en el test.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzIiQXVoWGs_","executionInfo":{"status":"ok","timestamp":1764851764297,"user_tz":-60,"elapsed":23758,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"9313c27e-6783-4a4f-fb7f-e7fbb0781cf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicciones generadas: 184\n","Filas en sample_submission: 184\n","¬°Archivo 'submission_stacking_opt1.csv' guardado con √©xito!\n","   ID  label\n","0   0      4\n","1   1      0\n","2   2      0\n","3   3      3\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","ENTRENAMIENTO Y PREDICCI√ìN SOBRE TEST SET CON SVM Y XGBOOST COMO META-MODELO"],"metadata":{"id":"aeoqus04Yk1F"}},{"cell_type":"code","source":["best_svm = SVC(\n","    C=1,\n","    gamma=0.05,\n","    kernel='rbf',\n","    class_weight=None,\n","    probability=True,\n","    random_state=42)\n","\n","# 2. DEFINIMOS EL META-MODELO\n","meta_learner = XGBClassifier(\n","    n_estimators=100,\n","    max_depth=3,          # Poca profundidad para evitar memorizar\n","    learning_rate=0.05,   # Aprendizaje suave\n","    eval_metric='mlogloss',\n","    use_label_encoder=False,\n","    random_state=42\n",")\n","\n","# 3. EL STACKING DEFINITIVO (√Årboles + SVM)\n","print(\"üöÄ Entrenando Stacking Classifier con SVM...\")\n","\n","stacking_clf = StackingClassifier(\n","    estimators=[\n","        ('lr', best_lr),\n","        ('rf', best_rf),\n","        ('xgb', best_xgb),\n","        ('brf', best_brf),\n","        ('eec', best_eec),\n","        ('svm', best_svm)\n","    ],\n","    final_estimator=meta_learner,\n","    cv=5,\n","    n_jobs=-1,\n","    passthrough=False\n",")\n","\n","# Entrenamos con los datos PRUNED (tu mejor preprocesado)\n","stacking_clf.fit(X_train_prep, y_train)\n","print(\"‚úÖ Entrenamiento finalizado.\")\n","\n","if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_stacking_pruned_opt2.csv\", index=False)\n","    print(\"¬°Archivo 'submission_stacking_pruned_opt2.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden. Revisa si se borraron filas en el test.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQYbJcLLYvTK","executionInfo":{"status":"ok","timestamp":1764852348375,"user_tz":-60,"elapsed":23727,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"8655456a-3bd7-4691-cc0c-e5b5522fccc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Entrenando Stacking Classifier con SVM...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:45:47] WARNING: /workspace/src/learner.cc:790: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Entrenamiento finalizado.\n","¬°Archivo 'submission_stacking_pruned_opt2.csv' guardado con √©xito!\n","   ID  label\n","0   0      4\n","1   1      0\n","2   2      0\n","3   3      3\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","\n","### DEFINICI√ìN MODELOS PREVIO AL VOTING\n","\n","---"],"metadata":{"id":"kQIEiB3XcXa4"}},{"cell_type":"code","source":["#!pip install catboost"],"metadata":{"id":"Z1jDJliQdCSY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","    from catboost import CatBoostClassifier\n","    CATBOOST_AVAILABLE = True\n","except ImportError:\n","    CATBOOST_AVAILABLE = False\n","    print(\"‚ö†Ô∏è CatBoost no instalado. Usaremos XGBoost en su lugar.\")\n","\n","best_svm = SVC(\n","    C=1,\n","    gamma=0.05,\n","    kernel='rbf',\n","    probability=True, # OBLIGATORIO para Soft Voting\n","    random_state=42\n",")\n","\n","\n","best_lr = LogisticRegression(\n","    C=0.1,\n","    solver='lbfgs',\n","    max_iter=1000,\n","    random_state=42\n",")\n","\n","\n","best_rf = RandomForestClassifier(\n","    n_estimators=200,\n","    max_depth=5,\n","    class_weight='balanced',\n","    random_state=42\n",")\n","\n","# El Especialista en Boosting (CatBoost o tu XGBoost anterior)\n","if CATBOOST_AVAILABLE:\n","    print(\"üê± Configurando CatBoost...\")\n","    # CatBoost suele funcionar bien con par√°metros por defecto\n","    best_boost = CatBoostClassifier(\n","        iterations=500,\n","        depth=4,\n","        learning_rate=0.05,\n","        loss_function='MultiClass',\n","        verbose=0,\n","        random_seed=42\n","    )\n","else:\n","    # Tu XGBoost anterior\n","    best_boost = best_xgb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhTMC86GcuqY","executionInfo":{"status":"ok","timestamp":1764853426813,"user_tz":-60,"elapsed":38,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"8a31ae52-3a61-419b-de7f-63d32efaebba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üê± Configurando CatBoost...\n"]}]},{"cell_type":"markdown","source":["---\n","ENTRENAMIENTO Y PREDICCI√ìN SOBRE TEST SET\n","\n","---"],"metadata":{"id":"P4faLrKrc2v6"}},{"cell_type":"code","source":["from sklearn.ensemble import VotingClassifier\n","voting_clf = VotingClassifier(\n","    estimators=[\n","        ('svm', best_svm),\n","        ('lr', best_lr),\n","        ('rf', best_rf),\n","        ('boost', best_boost)\n","    ],\n","    voting='soft', # Usa probabilidades\n","    weights=[4, 1, 1, 1],\n","    n_jobs=-1\n",")\n","\n","\n","voting_clf.fit(X_train_prep, y_train)\n","\n","y_test_pred = voting_clf.predict(X_test_prep)\n","\n","if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_voting_pruned_opt1.csv\", index=False)\n","    print(\"¬°Archivo 'submission_voting_pruned_opt1.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden. Revisa si se borraron filas en el test.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TxOeqeXsc6t5","executionInfo":{"status":"ok","timestamp":1764853468573,"user_tz":-60,"elapsed":9717,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"c5a81630-9eb5-430b-d855-2c15db161442"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["¬°Archivo 'submission_voting_pruned_opt1.csv' guardado con √©xito!\n","   ID  label\n","0   0      2\n","1   1      0\n","2   2      0\n","3   3      2\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","VOTING SIN BOOSTING Y RF\n","\n","---"],"metadata":{"id":"LrHdoZLjeILB"}},{"cell_type":"code","source":["best_svm = SVC(\n","    C=1,\n","    gamma=0.05,\n","    kernel='rbf',\n","    probability=True,  # Vital para mezclar con Soft Voting\n","    random_state=42)\n","\n","best_lr = LogisticRegression(\n","    C=0.08,\n","    solver='lbfgs',\n","    class_weight=None,\n","    random_state=42,\n","    max_iter=1000)"],"metadata":{"id":"2Nc8yu1IfRoT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["voting_clf = VotingClassifier(\n","    estimators=[\n","        ('svm', best_svm),\n","        ('lr', best_lr)\n","    ],\n","    voting='soft',         # Suma de probabilidades\n","    weights=[4, 1],        # <--- CLAVE: SVM vale 4 veces m√°s. LR solo desempata.\n","    n_jobs=-1\n",")\n","\n","voting_clf.fit(X_train_prep, y_train)\n","\n","y_test_pred = voting_clf.predict(X_test_prep)\n","\n","if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_voting_pruned_opt_2.csv\", index=False)\n","    print(\"¬°Archivo 'submission_logreg_pruned_opt_2.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgfJ1rz2ffoW","executionInfo":{"status":"ok","timestamp":1764854034405,"user_tz":-60,"elapsed":8215,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"1235dcfc-b1ce-4d56-c7bc-a5b2231fb108"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["¬°Archivo 'submission_logreg_pruned_opt_2.csv' guardado con √©xito!\n","   ID  label\n","0   0      3\n","1   1      0\n","2   2      0\n","3   3      2\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","## PSEUDO-LABELLING SVM\n","\n","---"],"metadata":{"id":"VCy7nm3Id7Qx"}},{"cell_type":"code","source":["# MEJOR MODELO (SVM 0.565)\n","best_svm = SVC(\n","    C=1,\n","    gamma=0.05,\n","    kernel='rbf',\n","    probability=True,\n","    random_state=42)\n","\n","# 2. ENTRENAMIENTO INICIAL (Ronda 1)\n","print(\"Ronda 1: Entrenando SVM con datos originales...\")\n","best_svm.fit(X_train_prep, y_train)\n","\n","# 3. GENERAR PSEUDO-LABELS\n","print(\"Generando predicciones de confianza sobre el Test...\")\n","y_test_proba = best_svm.predict_proba(X_test_prep)\n","y_test_pred = best_svm.predict(X_test_prep)\n","\n","# Definimos un umbral de confianza alto (ej. 70% por problema d√≠fic\n","# Solo confiamos en el modelo si est√° muy seguro.\n","CONFIDENCE_THRESHOLD = 0.70\n","\n","# Identificamos los √≠ndices del test donde la confianza supera el umbral\n","# np.max(y_test_proba, axis=1) nos da la probabilidad de la clase ganadora\n","confident_indices = np.where(np.max(y_test_proba, axis=1) > CONFIDENCE_THRESHOLD)[0]\n","\n","print(f\"Se han encontrado {len(confident_indices)} muestras 'seguras' en el Test para a√±adir al Train.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70BnnLaSeHLk","executionInfo":{"status":"ok","timestamp":1764937895899,"user_tz":-60,"elapsed":397,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"99f6ef75-86bc-44f7-b033-c32c16dd7a6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ronda 1: Entrenando SVM con datos originales...\n","Generando predicciones de confianza sobre el Test...\n","Se han encontrado 61 muestras 'seguras' en el Test para a√±adir al Train.\n"]}]},{"cell_type":"code","source":["# 4. CREAR NUEVO DATASET DE ENTRENAMIENTO (Train + Pseudo-Test)\n","if len(confident_indices) > 0:\n","    # Extraemos las features y las predicciones de esas filas seguras\n","    X_pseudo = X_test_prep.iloc[confident_indices]\n","    y_pseudo = y_test_pred[confident_indices]\n","\n","    # Convertimos y_pseudo a Series compatible con y_train\n","    y_pseudo = pd.Series(y_pseudo, index=X_pseudo.index)\n","\n","    # Concatenamos\n","    X_train_augmented = pd.concat([X_train_prep, X_pseudo])\n","    y_train_augmented = pd.concat([y_train, y_pseudo])\n","\n","    # Barajamos para que el modelo no aprenda orden\n","    X_train_augmented, y_train_augmented = shuffle(X_train_augmented, y_train_augmented, random_state=42)\n","\n","    print(f\"Nuevo tama√±o de Train: {len(X_train_augmented)} (Original: {len(X_train_prep)})\")\n","\n","    # 5. RE-ENTRENAMIENTO\n","    print(\" Ronda 2: Re-entrenando SVM con datos aumentados (Pseudo-Labeling)...\")\n","    best_svm.fit(X_train_augmented, y_train_augmented)\n","else:\n","    print(\"No hubo suficientes predicciones seguras. Se mantiene el modelo original.\")\n","\n","print(\"Generando predicciones finales...\")\n","y_final_pred = best_svm.predict(X_test_prep)\n","\n","if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_svm_labelling_pruned_opt_1.csv\", index=False)\n","    print(\"¬°Archivo 'submission_svm_labelling_pruned_opt_1.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQrdnczVegeB","executionInfo":{"status":"ok","timestamp":1764937911938,"user_tz":-60,"elapsed":192,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"5759e0a4-1473-4f3f-8607-ffb5ba9cf9c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nuevo tama√±o de Train: 793 (Original: 732)\n"," Ronda 2: Re-entrenando SVM con datos aumentados (Pseudo-Labeling)...\n","Generando predicciones finales...\n","¬°Archivo 'submission_svm_labelling_pruned_opt_1.csv' guardado con √©xito!\n","   ID  label\n","0   0      3\n","1   1      0\n","2   2      0\n","3   3      2\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","\n","## SVM OPTIMIZADO Y PRUNED + STACKING FULL DATA\n","\n","---"],"metadata":{"id":"4Cwe8oa9h0e8"}},{"cell_type":"code","source":["#1. SVM con mejor rendimiento bajo preprocesado avanzado e inginer√≠a de caracter√≠sticas\n","# X_train_prep y X_test_prep ya existen.\n","best_svm = SVC(\n","    C=1,\n","    gamma=0.05,\n","    kernel='rbf',\n","    class_weight=None,\n","    probability=True,\n","    random_state=42\n",")\n","\n","# Entrenamos con los datos limpios y podados\n","best_svm.fit(X_train_prep, y_train)\n","\n","# Obtenemos PROBABILIDADES (no etiquetas)\n","probs_svm = best_svm.predict_proba(X_test_prep)\n","print(\"Probabilidades SVM calculadas.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j90Gcpd5j9xq","executionInfo":{"status":"ok","timestamp":1764939619923,"user_tz":-60,"elapsed":158,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"07c575b3-38b1-4036-cfee-7f88164f4d73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilidades SVM calculadas.\n"]}]},{"cell_type":"code","source":["# 2. Preparamos los datos \"sucios\" (completos pero no rotos) para el Stacking\n","# Usamos df (train) y df_test (test) originales, solo imputando nulos b√°sicos\n","# sin borrar columnas ni ingenier√≠a compleja.\n","\n","# Limpieza Train\n","df_clean = limpieza_inicial(df)\n","X_full_train = df_clean.drop('label', axis=1) if 'label' in df_clean.columns else df_clean\n","y_full_train = df_clean['label'] if 'label' in df_clean.columns else y_train\n","\n","# Limpieza Test\n","df_test_clean_initial = limpieza_inicial(df_test)\n","X_full_test = df_test_clean_initial.copy()\n","if 'label' in X_full_test.columns:\n","    X_full_test = X_full_test.drop('label', axis=1)\n","\n","# Aplicamos correcciones fisiol√≥gicas y outliers (m√≠nimo)\n","X_full_train = limpiar_ceros_fisiologicos(X_full_train)\n","X_full_train = clipear_outliers(X_full_train)\n","\n","X_full_test = limpiar_ceros_fisiologicos(X_full_test)\n","X_full_test = clipear_outliers(X_full_test)\n","\n","# Imputaci√≥n simple (Mediana) para rellenar los NaNs generados\n","imputer_stacking = SimpleImputer(strategy='median')\n","X_full_train = pd.DataFrame(imputer_stacking.fit_transform(X_full_train), columns=X_full_train.columns)\n","X_full_test = pd.DataFrame(imputer_stacking.transform(X_full_test), columns=X_full_test.columns)"],"metadata":{"id":"1i3XQruQkgQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Definici√≥n stacking del 0.57\n","\n","lr_base = LogisticRegression(C=1, penalty='l2', solver='lbfgs', max_iter=1000, random_state=42)\n","rf_base = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=5, class_weight='balanced', random_state=42)\n","xgb_base = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=1.0, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n","brf_base = BalancedRandomForestClassifier(n_estimators=200, min_samples_split=2, random_state=42)\n","eec_base = EasyEnsembleClassifier(n_estimators=10, sampling_strategy='auto', random_state=42)\n","\n","# 2.3 Construimos el Stacking\n","stacking_clf = StackingClassifier(\n","    estimators=[\n","        ('lr', lr_base),\n","        ('rf', rf_base),\n","        ('xgb', xgb_base),\n","        ('brf', brf_base),\n","        ('eec', eec_base)\n","    ],\n","    final_estimator=LogisticRegression(max_iter=1000),\n","    cv=5,\n","    n_jobs=-1\n",")\n","\n","# Entrenamos con los datos COMPLETOS pero SANEADOS\n","stacking_clf.fit(X_full_train, y_full_train)\n","\n","# Obtenemos PROBABILIDADES\n","probs_stacking = stacking_clf.predict_proba(X_full_test)\n","print(\"Probabilidades Stacking calculadas.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8GNnl74mbSE","executionInfo":{"status":"ok","timestamp":1764939695669,"user_tz":-60,"elapsed":19244,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"fe1e53f5-1691-43e9-c764-3d494e9d4685"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilidades Stacking calculadas.\n"]}]},{"cell_type":"code","source":["# Realizando Blending H√≠brido\n","\n","W_SVM = 0.5      # Peso del SVM (imputaci√≥n avanzada, inginier√≠a de caracter√≠sticas y variables pruned)\n","W_STACKING = 0.5 # Peso del Stacking (datos completos y \"sucios\")\n","\n","print(f\"   Pesos -> SVM: {W_SVM} | Stacking: {W_STACKING}\")\n","\n","probs_final = (probs_svm * W_SVM) + (probs_stacking * W_STACKING)\n","y_pred_final = np.argmax(probs_final, axis=1)\n","\n","\n","if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_hibrido_svm_stacking_1.csv\", index=False)\n","    print(\"¬°Archivo 'submission_hibrido_svm_stacking_1.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxJuyBNGmuPf","executionInfo":{"status":"ok","timestamp":1764939889238,"user_tz":-60,"elapsed":8,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"9530d053-32f3-45b1-e5ad-91e702dfeecd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   Pesos -> SVM: 0.5 | Stacking: 0.5\n","¬°Archivo 'submission_hibrido_svm_stacking_1.csv' guardado con √©xito!\n","   ID  label\n","0   0      3\n","1   1      0\n","2   2      0\n","3   3      2\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","PRUEBAS CON DIFERENTES PESOS\n","\n","---"],"metadata":{"id":"R9I05_MDoU7z"}},{"cell_type":"code","source":["# ESTRATEGIA 1: Favor Stacking (70% Stacking - 30% SVM)\n","# L√≥gica: El Stacking tiene 0.57. Le damos el mando. El SVM solo corrige si el Stacking duda mucho.\n","w_stack = 0.7\n","w_svm = 0.3\n","probs_1 = (probs_stacking * w_stack) + (probs_svm * w_svm)\n","pred_1 = np.argmax(probs_1, axis=1)\n","\n","# 70/30 empeora resultados. Se abandona la estrategia\n","\n","# # ESTRATEGIA 2: Dominio Stacking (85% Stacking - 15% SVM)\n","# # L√≥gica: Confiamos casi ciegamente en el 0.57, pero dejamos un 15% por si el SVM\n","# # ve algo geom√©trico muy obvio que el Stacking se perdi√≥.\n","# w_stack2 = 0.85\n","# w_svm2 = 0.15\n","# probs_2 = (probs_stacking * w_stack2) + (probs_svm * w_svm2)\n","# pred_2 = np.argmax(probs_2, axis=1)\n","\n","# # ESTRATEGIA 3: Favor SVM Ligero (60% SVM - 40% Stacking)\n","# # L√≥gica: Quiz√°s el 50/50 fall√≥ por poco. Probamos darle un empuj√≥n al SVM\n","# # pero manteniendo una base fuerte del Stacking.\n","# w_stack3 = 0.4\n","# w_svm3 = 0.6\n","# probs_3 = (probs_stacking * w_stack3) + (probs_svm * w_svm3)\n","# pred_3 = np.argmax(probs_3, axis=1)\n","\n","# --- GENERACI√ìN DE ARCHIVOS ---\n","\n","def save_submission(pred_array, filename):\n","    if len(pred_array) == len(df_test): # O len(submission)\n","        # Recuperamos IDs correctos\n","        ids = df_test.index if 'ID' not in df_test.columns else df_test['ID']\n","\n","        sub = pd.DataFrame({\n","            \"ID\": ids,\n","            \"label\": pred_array.astype(int)\n","        })\n","        sub.to_csv(filename, index=False)\n","        print(f\"‚úÖ Guardado: {filename}\")\n","    else:\n","        print(f\"‚ùå Error dimensiones en {filename}\")\n","\n","save_submission(pred_1, \"sub_weight_70Stack_30SVM.csv\")\n","save_submission(pred_2, \"sub_weight_85Stack_15SVM.csv\")\n","save_submission(pred_3, \"sub_weight_40Stack_60SVM.csv\")\n","\n","print(\"\\nüöÄ ¬°Archivos listos!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kyHPn6uxoTWi","executionInfo":{"status":"ok","timestamp":1764940228389,"user_tz":-60,"elapsed":24,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"286b2b85-053f-45ee-cc5f-b37c9a2cad44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Guardado: sub_weight_70Stack_30SVM.csv\n","‚úÖ Guardado: sub_weight_85Stack_15SVM.csv\n","‚úÖ Guardado: sub_weight_40Stack_60SVM.csv\n","\n","üöÄ ¬°Archivos listos!\n"]}]},{"cell_type":"markdown","source":["---\n","\n","ESTRATEGIA RANK BLENDING\n","\n","---"],"metadata":{"id":"LDqtI9X_pq-P"}},{"cell_type":"code","source":["\n","def get_rank_probs(probs):\n","    \"\"\"Convierte probabilidades en rankings normalizados (0 a 1)\"\"\"\n","    # Aplicamos ranking por columna (por cada clase)\n","    ranked = np.apply_along_axis(rankdata, 0, probs)\n","    return ranked / len(probs) # Normalizamos entre 0 y 1\n","\n","# Pre-calculamos los rankings (Esto pone a ambos modelos en igualdad de condiciones)\n","# Asumimos que probs_stacking y probs_svm est√°n en memoria\n","rank_stacking = get_rank_probs(probs_stacking)\n","rank_svm = get_rank_probs(probs_svm)\n","\n","# ESTRATEGIA 1: Protecci√≥n del L√≠der (90% Stacking - 10% SVM)\n","# Si el 70/30 fall√≥, reducimos dr√°sticamente la influencia del SVM.\n","# Usamos probabilidades directas aqu√≠, solo un toque sutil de SVM.\n","w_stack1 = 0.90\n","w_svm1 = 0.10\n","probs_1 = (probs_stacking * w_stack1) + (probs_svm * w_svm1)\n","pred_1 = np.argmax(probs_1, axis=1)\n","\n","# ESTRATEGIA 2: Rank Blending (50% - 50%) - RECOMENDADA\n","# Al usar rankings, eliminamos el \"ruido\" de la confianza excesiva del SVM.\n","# Esto suele funcionar mejor cuando los modelos \"chocan\".\n","probs_2 = (rank_stacking * 0.5) + (rank_svm * 0.5)\n","pred_2 = np.argmax(probs_2, axis=1)\n","\n","# ESTRATEGIA 3: Rank Blending Ponderado (70% Stacking - 30% SVM)\n","# Lo mismo que tu intento anterior, pero en espacio de Rankings.\n","# Deber√≠a ser mucho m√°s estable que el 0.54 que obtuviste.\n","probs_3 = (rank_stacking * 0.7) + (rank_svm * 0.3)\n","pred_3 = np.argmax(probs_3, axis=1)\n","\n","# --- GENERACI√ìN DE ARCHIVOS ---\n","\n","# def save_submission(pred_array, filename):\n","#     if len(pred_array) == len(df_test):\n","#         ids = df_test.index if 'ID' not in df_test.columns else df_test['ID']\n","\n","#         sub = pd.DataFrame({\n","#             \"ID\": ids,\n","#             \"label\": pred_array.astype(int)\n","#         })\n","#         sub.to_csv(filename, index=False)\n","#         print(f\"Guardado: {filename}\")\n","#     else:\n","#         print(f\"Error dimensiones en {filename}\")\n","\n","# save_submission(pred_1, \"sub_RANK_90Stack_10SVM.csv\")\n","# save_submission(pred_2, \"sub_RANK_50Stack_50SVM.csv\")\n","# save_submission(pred_3, \"sub_RANK_70Stack_30SVM.csv\")\n","\n","# print(\"\\n¬°Archivos generados! \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AexupNVIpqMD","executionInfo":{"status":"ok","timestamp":1764940728593,"user_tz":-60,"elapsed":70,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"e1315dc5-3169-4cb7-84e4-c3add7b8ba26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Guardado: sub_RANK_90Stack_10SVM.csv\n","Guardado: sub_RANK_50Stack_50SVM.csv\n","Guardado: sub_RANK_70Stack_30SVM.csv\n","\n","¬°Archivos generados! \n"]}]},{"cell_type":"markdown","source":["---\n","\n","CORRECI√ìN DEL STACKING EN CASO DE DUDA USANDO EL SVM\n","\n","---"],"metadata":{"id":"suL0XXHHrqqH"}},{"cell_type":"code","source":["\n","# 1. Obtenemos las predicciones base (Clase con mayor probabilidad)\n","pred_stacking = np.argmax(probs_stacking, axis=1)\n","pred_svm = np.argmax(probs_svm, axis=1)\n","\n","# 2. Medimos la \"Seguridad\" de cada modelo (Probabilidad m√°xima de la fila)\n","confianza_stacking = np.max(probs_stacking, axis=1)\n","confianza_svm = np.max(probs_svm, axis=1)\n","\n","# # ESTRATEGIA 1: Rescate Conservador (Umbral 0.5 / 0.8)\n","# # L√≥gica: Si Stacking duda (<50%) y SVM est√° muy seguro (>80%), hacemos caso al SVM.\n","# preds_rescate_1 = pred_stacking.copy()\n","\n","# # M√°scara de correcci√≥n\n","# mask_1 = (confianza_stacking < 0.50) & (confianza_svm > 0.80)\n","# preds_rescate_1[mask_1] = pred_svm[mask_1]\n","\n","cambios_1 = np.sum(mask_1)\n","print(f\"ESTRATEGIA 1: Se han corregido {cambios_1} filas donde Stacking dudaba.\")\n","\n","# ESTRATEGIA 2: Rescate Moderado (Umbral 0.6 / 0.7)\n","# L√≥gica: Si Stacking no est√° muy claro (<60%) y SVM tiene una opini√≥n decente (>70%).\n","preds_rescate_2 = pred_stacking.copy()\n","\n","mask_2 = (confianza_stacking < 0.60) & (confianza_svm > 0.70)\n","preds_rescate_2[mask_2] = pred_svm[mask_2]\n","\n","cambios_2 = np.sum(mask_2)\n","print(f\"ESTRATEGIA 2: Se han corregido {cambios_2} filas (Umbrales m√°s suaves).\")\n","\n","# # ESTRATEGIA 3: El \"Juez Supremo\" (Max Confidence Wins)\n","# # L√≥gica: Simplemente nos quedamos con la predicci√≥n del modelo que est√© m√°s seguro\n","# # en esa fila espec√≠fica. Si SVM tiene 0.9 y Stacking 0.6, gana SVM.\n","# # Esto evita promedios. Es uno u otro.\n","# preds_supremo = []\n","# for i in range(len(probs_stacking)):\n","#     if confianza_svm[i] > confianza_stacking[i]:\n","#         preds_supremo.append(pred_svm[i])\n","#     else:\n","#         preds_supremo.append(pred_stacking[i])\n","\n","# preds_supremo = np.array(preds_supremo)\n","# cambios_3 = np.sum(preds_supremo != pred_stacking)\n","# print(f\"ESTRATEGIA 3: SVM ha ganado la discusi√≥n en {cambios_3} filas por mayor confianza.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i_C9BURer0-5","executionInfo":{"status":"ok","timestamp":1764941113930,"user_tz":-60,"elapsed":40,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"4b9524b7-4620-4ecc-aa03-62339d001393"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ESTRATEGIA 1: Se han corregido 0 filas donde Stacking dudaba.\n","ESTRATEGIA 2: Se han corregido 2 filas (Umbrales m√°s suaves).\n","ESTRATEGIA 3: SVM ha ganado la discusi√≥n en 29 filas por mayor confianza.\n"]}]},{"cell_type":"code","source":["def save_submission(pred_array, filename):\n","    if len(pred_array) == len(df_test):\n","        ids = df_test.index if 'ID' not in df_test.columns else df_test['ID']\n","\n","        sub = pd.DataFrame({\n","            \"ID\": ids,\n","            \"label\": pred_array.astype(int)\n","        })\n","        sub.to_csv(filename, index=False)\n","        print(f\"Guardado: {filename}\")\n","    else:\n","        print(f\"Error dimensiones en {filename}\")\n","\n","save_submission(preds_rescate_1, \"sub_RESCUE_Conservative.csv\")\n","save_submission(preds_rescate_2, \"sub_RESCUE_Moderate.csv\")\n","save_submission(preds_supremo, \"sub_MAX_CONFIDENCE.csv\")\n","\n","print(\"\\n¬°Archivos generados! Estas estrategias NO promedian, solo sustituyen.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYiGHyyqr6l6","executionInfo":{"status":"ok","timestamp":1764941213895,"user_tz":-60,"elapsed":26,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"58ffde4e-b955-419f-9b7d-9963bf30a3f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Guardado: sub_RESCUE_Conservative.csv\n","Guardado: sub_RESCUE_Moderate.csv\n","Guardado: sub_MAX_CONFIDENCE.csv\n","\n","¬°Archivos generados! Estas estrategias NO promedian, solo sustituyen.\n"]}]},{"cell_type":"markdown","source":["---\n","## ENSAMBLE JER√ÅRQUICO\n","\n","---"],"metadata":{"id":"mMRTllHiuKyM"}},{"cell_type":"code","source":["print(\"\\n FASE 1: Entrenando SVM Binario\")\n","\n","# Creamos el target binario\n","# 0 -> 0 (Sano)\n","# 1,2,3,4 -> 1 (Enfermo)\n","y_train_binary = (y_train > 0).astype(int)\n","\n","# Configuraci√≥n SVM optimizada\n","svm_binary = SVC(\n","    C=1,\n","    gamma=0.05,\n","    kernel='rbf',\n","    probability=True,\n","    random_state=42\n",")\n","\n","# Entrenamos con los datos PREP (Pruned)\n","svm_binary.fit(X_train_prep, y_train_binary)\n","\n","# Predecimos sobre el Test Prep\n","# Si predice 0 es Sano. Si predice 1 es \"Algo tiene\".\n","preds_binary_svm = svm_binary.predict(X_test_prep)\n","\n","print(f\"   -> SVM ha clasificado como 'Sanos' (0) a {np.sum(preds_binary_svm == 0)} pacientes.\")\n","print(f\"   -> SVM ha clasificado como 'Enfermos' (1+) a {np.sum(preds_binary_svm == 1)} pacientes.\")"],"metadata":{"id":"wKzkM1_O7KbH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764945725490,"user_tz":-60,"elapsed":329,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"02f359f7-6968-44c4-f607-14ec89245838"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," FASE 1: Entrenando SVM Binario\n","   -> SVM ha clasificado como 'Sanos' (0) a 80 pacientes.\n","   -> SVM ha clasificado como 'Enfermos' (1+) a 104 pacientes.\n"]}]},{"cell_type":"code","source":["print(\"\\n FASE 2: Entrenando Stacking Multiclase...\")\n","\n","# 2.1 Preparar Datos Completos (Raw + Limpieza B√°sica + Imputaci√≥n Simple)\n","df_clean = limpieza_inicial(df)\n","X_full_train = df_clean.drop('label', axis=1) if 'label' in df_clean.columns else df_clean\n","y_full_train = df_clean['label'] if 'label' in df_clean.columns else y_train\n","\n","df_test_clean_initial = limpieza_inicial(df_test)\n","X_full_test = df_test_clean_initial.copy()\n","if 'label' in X_full_test.columns: X_full_test = X_full_test.drop('label', axis=1)\n","\n","# Limpieza m√≠nima\n","X_full_train = limpiar_ceros_fisiologicos(X_full_train)\n","X_full_train = clipear_outliers(X_full_train)\n","X_full_test = limpiar_ceros_fisiologicos(X_full_test)\n","X_full_test = clipear_outliers(X_full_test)\n","\n","# Imputaci√≥n Simple\n","imputer = SimpleImputer(strategy='median')\n","X_full_train = pd.DataFrame(imputer.fit_transform(X_full_train), columns=X_full_train.columns)\n","X_full_test = pd.DataFrame(imputer.transform(X_full_test), columns=X_full_test.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nv3x2qNK70Wg","executionInfo":{"status":"ok","timestamp":1764945727017,"user_tz":-60,"elapsed":258,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"9984f531-9f70-4e80-f8c0-d3e510e4f2a5"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," FASE 2: Entrenando Stacking Multiclase...\n"]}]},{"cell_type":"code","source":["lr_base = LogisticRegression(C=1, penalty='l2', solver='lbfgs', max_iter=1000, random_state=42)\n","rf_base = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=5, class_weight='balanced', random_state=42)\n","xgb_base = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=1.0, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n","brf_base = BalancedRandomForestClassifier(n_estimators=200, min_samples_split=2, random_state=42)\n","eec_base = EasyEnsembleClassifier(n_estimators=10, sampling_strategy='auto', random_state=42)\n","\n","stacking_clf = StackingClassifier(\n","    estimators=[\n","        ('lr', lr_base), ('rf', rf_base), ('xgb', xgb_base), ('brf', brf_base), ('eec', eec_base)\n","    ],\n","    final_estimator=LogisticRegression(max_iter=1000),\n","    cv=5, n_jobs=-1\n",")\n","\n","# Entrenamos con TODOS los datos (0-4) para que aprenda el contexto global\n","stacking_clf.fit(X_full_train, y_full_train)\n","\n","# Predicciones Multiclase\n","preds_multiclass_stacking = stacking_clf.predict(X_full_test)\n"],"metadata":{"id":"lFRh2-I38D5b","executionInfo":{"status":"ok","timestamp":1764945758363,"user_tz":-60,"elapsed":29526,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}}},"execution_count":125,"outputs":[]},{"cell_type":"code","source":["print(\"\\n FASE 3: Combinando Resultados con estrategia A\")\n","\n","# 1. Empezamos con las predicciones del Stacking (que sabe distinguir 1,2,3,4)\n","final_predictions = preds_multiclass_stacking.copy()\n","\n","# 2. APLICAMOS EL FILTRO DEL SVM:\n","# Donde el SVM dijo \"0\" (Sano), FORZAMOS que sea 0,\n","# ignorando lo que diga el Stacking (incluso si el Stacking dijo 1 o 2).\n","mask_sanos_svm = (preds_binary_svm == 0)\n","final_predictions[mask_sanos_svm] = 0\n","\n","#  ¬øQu√© pasa si SVM dice \"Enfermo\" pero Stacking dice \"0\"?\n","# Opci√≥n A: Dejar el 0 del Stacking (Asumimos que SVM detect√≥ algo raro pero Stacking confirm√≥ que no es grave).\n","\n","# DE MOMENTO: Usamos Opci√≥n A (Respetamos el 0 del stacking si pasa el filtro inverso),\n","# pero la prioridad es limpiar los falsos positivos con el SVM.\n","\n","print(\"   Integraci√≥n completada.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FfyjOg_8Iaa","executionInfo":{"status":"ok","timestamp":1764945393929,"user_tz":-60,"elapsed":16,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"8220a668-4e52-4dea-c831-04b6e3e08256"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," FASE 3: Combinando Resultados\n","   Integraci√≥n completada.\n"]}]},{"cell_type":"code","source":["if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_Hierarchical_SVM_Stacking.csv.csv\", index=False)\n","    print(\"¬°Archivo 'submission_Hierarchical_SVM_Stacking.csv.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-m4AWxE8euR","executionInfo":{"status":"ok","timestamp":1764945442695,"user_tz":-60,"elapsed":22,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"d7519f4d-bfb1-440d-981b-89dc35ba3228"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["¬°Archivo 'submission_Hierarchical_SVM_Stacking.csv.csv' guardado con √©xito!\n","   ID  label\n","0   0      3\n","1   1      0\n","2   2      0\n","3   3      2\n","4   4      0\n"]}]},{"cell_type":"code","source":["print(\"\\n FASE 3: Combinando Resultados (Estrategia B: Correcci√≥n Bidireccional)\")\n","\n","# 1. Empezamos con las predicciones del Stacking\n","final_predictions = preds_multiclass_stacking.copy()\n","\n","# 2. FILTRO 1: SANAR FALSOS POSITIVOS\n","# Si SVM dice \"0\" (Sano), forzamos 0.\n","mask_sanos_svm = (preds_binary_svm == 0)\n","num_correciones_a_0 = np.sum((final_predictions != 0) & mask_sanos_svm)\n","final_predictions[mask_sanos_svm] = 0\n","print(f\"   -> {num_correciones_a_0} pacientes corregidos a SANO (0) por el SVM.\")\n","\n","# 3. FILTRO 2: DETECTAR FALSOS NEGATIVOS (La Opci√≥n B)\n","# Si SVM dice \"Enfermo\" (1) PERO el Stacking dijo \"Sano\" (0), forzamos a 1.\n","mask_enfermos_svm = (preds_binary_svm == 1)\n","# Solo corregimos si el stacking dijo 0 (si dijo 2, 3 o 4 ya estamos de acuerdo en que est√° enfermo)\n","mask_correccion_1 = mask_enfermos_svm & (final_predictions == 0)\n","\n","num_correciones_a_1 = np.sum(mask_correccion_1)\n","final_predictions[mask_correccion_1] = 1 # Severidad m√≠nima\n","print(f\"   -> {num_correciones_a_1} pacientes corregidos a ENFERMO LEVE (1) porque el SVM detect√≥ riesgo.\")\n","\n","print(\"   Integraci√≥n completada.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KbJLKEHY9tBa","executionInfo":{"status":"ok","timestamp":1764945869181,"user_tz":-60,"elapsed":39,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"8f42d080-96f5-4fb9-cd88-354ede864da9"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," FASE 3: Combinando Resultados (Estrategia B: Correcci√≥n Bidireccional)\n","   -> 1 pacientes corregidos a SANO (0) por el SVM.\n","   -> 11 pacientes corregidos a ENFERMO LEVE (1) porque el SVM detect√≥ riesgo.\n","   Integraci√≥n completada.\n"]}]},{"cell_type":"code","source":["if len(y_test_pred) == len(submission):\n","    submission[\"label\"] = y_test_pred\n","    submission.to_csv(\"submission_Hierarchical_SVM_Stacking_OptionB.csv\", index=False)\n","    print(\"¬°Archivo 'submission_Hierarchical_SVM_Stacking_OptionB.csv' guardado con √©xito!\")\n","\n","    # Vista previa\n","    print(submission.head())\n","else:\n","    print(\"¬°ALERTA! Las dimensiones no coinciden.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHeHPwBt-DzQ","executionInfo":{"status":"ok","timestamp":1764945946529,"user_tz":-60,"elapsed":43,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"bb92e0dd-ec23-4777-c1d3-3a8fd846ee36"},"execution_count":127,"outputs":[{"output_type":"stream","name":"stdout","text":["¬°Archivo 'submission_Hierarchical_SVM_Stacking_OptionB.csv' guardado con √©xito!\n","   ID  label\n","0   0      3\n","1   1      0\n","2   2      0\n","3   3      2\n","4   4      0\n"]}]},{"cell_type":"code","source":["\n","print(\"‚ö° INICIANDO IMPLANTE QUIR√öRGICO (Base 0.57 + Correcci√≥n SVM) ‚ö°\")\n","\n","# =============================================================================\n","# 1. CARGAR LA BASE DE ORO (El archivo de 0.57)\n","# =============================================================================\n","# Aseg√∫rate de subir este archivo a tu entorno de Colab/Kaggle\n","file_path_best = \"/content/sub_RESCUE_Conservative.csv\"\n","\n","try:\n","    df_best = pd.read_csv(file_path_best)\n","    # Aseguramos que tenemos las etiquetas\n","    preds_base_057 = df_best['label'].values\n","    print(f\"‚úÖ Cargado archivo base (R√©cord 0.57): {len(preds_base_057)} predicciones.\")\n","except FileNotFoundError:\n","    raise FileNotFoundError(f\"‚ùå NO SE ENCUENTRA '{file_path_best}'. S√∫belo para continuar.\")\n","\n","# =============================================================================\n","# 2. RE-ENTRENAR SOLO EL SVM (Tu mejor discriminador)\n","# =============================================================================\n","# Usamos tu pipeline de preprocesado avanzado (Pruned) que ya tienes en memoria.\n","# Si X_train_prep / X_test_prep no est√°n definidos, el c√≥digo fallar√°.\n","# Aseg√∫rate de haber ejecutado el bloque de preprocesado antes.\n","\n","print(\"\\nüõ°Ô∏è Entrenando SVM Binario (Detector de Riesgo)...\")\n","\n","# Target Binario: 0=Sano, 1=Enfermo (Clases 1,2,3,4)\n","y_train_binary = (y_train > 0).astype(int)\n","\n","# Tu mejor configuraci√≥n SVM (Sin class_weight, como indicaste)\n","svm_binary = SVC(\n","    C=1,\n","    gamma=0.05,\n","    kernel='rbf',\n","    class_weight=None,\n","    probability=True,\n","    random_state=42\n",")\n","\n","svm_binary.fit(X_train_prep, y_train_binary)\n","preds_binary_svm = svm_binary.predict(X_test_prep)\n","\n","print(\"‚úÖ SVM entrenado y predicciones generadas.\")\n","\n","\n","# =============================================================================\n","# 3. APLICAR L√ìGICA JER√ÅRQUICA SOBRE EL ARCHIVO 0.57\n","# =============================================================================\n","print(\"\\nüîó FUSIONANDO RESULTADOS...\")\n","\n","final_preds = preds_base_057.copy()\n","cambios_totales = 0\n","\n","# REGLA 1: SI SVM DICE \"SANO\" (0) -> FORZAMOS 0\n","# (Corregimos falsos positivos del Stacking)\n","mask_force_0 = (preds_binary_svm == 0) & (final_preds != 0)\n","num_force_0 = np.sum(mask_force_0)\n","final_preds[mask_force_0] = 0\n","print(f\"   -> {num_force_0} pacientes corregidos a SANO (0).\")\n","\n","# REGLA 2: SI SVM DICE \"ENFERMO\" (1) Y STACKING DICE \"SANO\" (0) -> FORZAMOS 1\n","# (Corregimos falsos negativos del Stacking - Opci√≥n B)\n","mask_force_1 = (preds_binary_svm == 1) & (final_preds == 0)\n","num_force_1 = np.sum(mask_force_1)\n","final_preds[mask_force_1] = 1\n","print(f\"   -> {num_force_1} pacientes corregidos a ENFERMO LEVE (1).\")\n","\n","cambios_totales = num_force_0 + num_force_1\n","print(f\"üìä TOTAL CAMBIOS REALIZADOS SOBRE EL 0.57: {cambios_totales}\")\n","\n","\n","# =============================================================================\n","# 4. GENERAR ARCHIVO FINAL\n","# =============================================================================\n","if len(final_preds) == len(df_test):\n","    ids = df_test.index if 'ID' not in df_test.columns else df_test['ID']\n","\n","    sub = pd.DataFrame({\n","        \"ID\": ids,\n","        \"label\": final_preds.astype(int)\n","    })\n","\n","    filename = \"submission_Surgical_Graft_057_SVM.csv\"\n","    sub.to_csv(filename, index=False)\n","\n","    print(f\"\\nüèÜ ¬°Archivo '{filename}' generado!\")\n","    print(\"   Este archivo contiene la sabidur√≠a del Stacking (0.57) + la correcci√≥n del SVM.\")\n","    print(sub.head())\n","else:\n","    print(\"‚ùå Error de dimensiones.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSYTtpqa_MDY","executionInfo":{"status":"ok","timestamp":1764946168589,"user_tz":-60,"elapsed":185,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"10fe920a-5df6-4153-ad33-580657718167"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ö° INICIANDO IMPLANTE QUIR√öRGICO (Base 0.57 + Correcci√≥n SVM) ‚ö°\n","‚úÖ Cargado archivo base (R√©cord 0.57): 184 predicciones.\n","\n","üõ°Ô∏è Entrenando SVM Binario (Detector de Riesgo)...\n","‚úÖ SVM entrenado y predicciones generadas.\n","\n","üîó FUSIONANDO RESULTADOS...\n","   -> 1 pacientes corregidos a SANO (0).\n","   -> 11 pacientes corregidos a ENFERMO LEVE (1).\n","üìä TOTAL CAMBIOS REALIZADOS SOBRE EL 0.57: 12\n","\n","üèÜ ¬°Archivo 'submission_Surgical_Graft_057_SVM.csv' generado!\n","   Este archivo contiene la sabidur√≠a del Stacking (0.57) + la correcci√≥n del SVM.\n","   ID  label\n","0   0      2\n","1   1      0\n","2   2      0\n","3   3      3\n","4   4      0\n"]}]},{"cell_type":"code","source":["\n","print(\"‚ö° ENTRENANDO STACKING MEJORADO (Base 0.57 + SVM Integrado) ‚ö°\")\n","\n","# =============================================================================\n","# 1. PREPARACI√ìN DE DATOS (ESTILO \"SIMPLE\" DEL 0.57)\n","# =============================================================================\n","# Usamos la misma l√≥gica que funcion√≥ en el 0.57: limpieza m√≠nima + imputaci√≥n simple.\n","\n","cols_to_int = ['age', 'sex', 'cp', 'restecg']\n","rename_dict = {\n","    \"age\": \"edad\", \"sex\": \"sexo\", \"cp\": \"tipo_dolor_pecho\", \"trestbps\": \"tension_en_descanso\",\n","    \"chol\": \"colesterol\", \"fbs\": \"azucar\", \"restecg\": \"electro_en_descanso\",\n","    \"thalach\": \"latidos_por_minuto\", \"exang\": \"dolor_pecho_con_ejercicio\",\n","    \"oldpeak\": \"cambio_linea_corazon_ejercicio\", \"slope\": \"forma_linea_corazon_ejercicio\",\n","    \"ca\": \"num_venas_grandes\", \"thal\": \"estado_corazon_thal\"\n","}\n","\n","def limpieza_basica(df):\n","    df = df.copy()\n","    for col in df.columns:\n","        if col != 'label':\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","    df = df.rename(columns=rename_dict)\n","    df.replace([-9, -9.0], np.nan, inplace=True)\n","    return df\n","\n","# Cargar datos (Aseg√∫rate de que df y df_test est√©n cargados en tu entorno)\n","# Si no, descomenta las l√≠neas de carga:\n","df = pd.read_csv('/content/drive/MyDrive/Cupido_IA_project/train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/Cupido_IA_project/test.csv')\n","\n","df_clean = limpieza_basica(df)\n","df_test_clean = limpieza_basica(df_test)\n","\n","# Imputaci√≥n Simple (Mediana) - La clave del √©xito del 0.57\n","imputer = SimpleImputer(strategy='median')\n","\n","X = df_clean.drop('label', axis=1)\n","y = df_clean['label']\n","X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n","\n","# Preparar Test\n","if 'label' in df_test_clean.columns:\n","    df_test_clean = df_test_clean.drop('label', axis=1)\n","X_test_imputed = pd.DataFrame(imputer.transform(df_test_clean), columns=df_test_clean.columns)\n","\n","print(\"‚úÖ Datos preparados (Estrategia Simple).\")\n","\n","# =============================================================================\n","# 2. DEFINICI√ìN DE MODELOS CON TRATAMIENTO ESPEC√çFICO\n","# =============================================================================\n","# Aqu√≠ est√° el truco: El SVM necesita Scaler, los √Årboles no.\n","# Usamos Pipelines individuales para cada modelo base.\n","\n","# A. Modelos de √Årboles (Datos \"crudos\" imputados)\n","rf = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=5, class_weight='balanced', random_state=42)\n","xgb = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=1.0, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n","brf = BalancedRandomForestClassifier(n_estimators=200, min_samples_split=2, random_state=42)\n","eec = EasyEnsembleClassifier(n_estimators=10, sampling_strategy='auto', random_state=42)\n","\n","# B. Modelos Sensibles a Escala (SVM y LR) -> Llevan StandardScaler incorporado\n","svm_pipe = Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('svm', SVC(C=1, gamma=0.05, kernel='rbf', probability=True, random_state=42))\n","])\n","\n","lr_pipe = Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('lr', LogisticRegression(C=1, penalty='l2', solver='lbfgs', max_iter=1000, random_state=42))\n","])\n","\n","# =============================================================================\n","# 3. CONSTRUCCI√ìN DEL STACKING MEJORADO\n","# =============================================================================\n","print(\"üöÄ Entrenando Stacking V2 (LR + RF + XGB + BRF + EEC + SVM)...\")\n","\n","stacking_clf_v2 = StackingClassifier(\n","    estimators=[\n","        ('lr', lr_pipe),      # Pipeline con Scaler\n","        ('rf', rf),           # Sin Scaler\n","        ('xgb', xgb),         # Sin Scaler\n","        ('brf', brf),         # Sin Scaler\n","        ('eec', eec),         # Sin Scaler\n","        ('svm', svm_pipe)     # NUEVO: Pipeline con Scaler e Hiperpar√°metros √ìptimos\n","    ],\n","    # Meta-Learner: Usamos LogisticRegression 'balanced' para corregir sesgos finales\n","    final_estimator=LogisticRegression(max_iter=1000, class_weight='balanced'),\n","    cv=5,\n","    n_jobs=-1\n",")\n","\n","stacking_clf_v2.fit(X_imputed, y)\n","print(\"‚úÖ Entrenamiento completado.\")\n","\n","# =============================================================================\n","# 4. GENERAR PREDICCIONES\n","# =============================================================================\n","print(\"Generando submission...\")\n","y_pred_final = stacking_clf_v2.predict(X_test_imputed)\n","\n","# Obtener IDs\n","submission_ids = df_test.index if 'ID' not in df_test.columns else df_test['ID']\n","\n","sub = pd.DataFrame({\n","    \"ID\": submission_ids,\n","    \"label\": y_pred_final.astype(int)\n","})\n","\n","filename = \"submission_Integrated_Stacking_Plus_SVM.csv\"\n","sub.to_csv(filename, index=False)\n","\n","print(f\"üèÜ ¬°Archivo '{filename}' guardado!\")\n","print(\"   Estrategia: Stacking Original Mejorado (SVM a√±adido correctamente escalado)\")\n","print(sub.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nt1G_HePAOF7","executionInfo":{"status":"ok","timestamp":1764946453910,"user_tz":-60,"elapsed":17309,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"23fec7e5-1a19-4e36-c1bd-7436bb0c179e"},"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ö° ENTRENANDO STACKING MEJORADO (Base 0.57 + SVM Integrado) ‚ö°\n","‚úÖ Datos preparados (Estrategia Simple).\n","üöÄ Entrenando Stacking V2 (LR + RF + XGB + BRF + EEC + SVM)...\n","‚úÖ Entrenamiento completado.\n","Generando submission...\n","üèÜ ¬°Archivo 'submission_Integrated_Stacking_Plus_SVM.csv' guardado!\n","   Estrategia: Stacking Original Mejorado (SVM a√±adido correctamente escalado)\n","   ID  label\n","0   0      4\n","1   1      0\n","2   2      0\n","3   3      2\n","4   4      0\n"]}]},{"cell_type":"code","source":["\n","print(\"‚ö° ENTRENANDO STACKING AVANZADO: PIPELINES PARALELOS (SVM Pruned + √Årboles Raw) ‚ö°\")\n","\n","# =============================================================================\n","# 1. DEFINICI√ìN DE CLASES Y FUNCIONES DE PREPROCESADO AVANZADO (Para el SVM)\n","# =============================================================================\n","\n","cols_to_int = ['age', 'sex', 'cp', 'restecg']\n","rename_dict = {\n","    \"age\": \"edad\", \"sex\": \"sexo\", \"cp\": \"tipo_dolor_pecho\", \"trestbps\": \"tension_en_descanso\",\n","    \"chol\": \"colesterol\", \"fbs\": \"azucar\", \"restecg\": \"electro_en_descanso\",\n","    \"thalach\": \"latidos_por_minuto\", \"exang\": \"dolor_pecho_con_ejercicio\",\n","    \"oldpeak\": \"cambio_linea_corazon_ejercicio\", \"slope\": \"forma_linea_corazon_ejercicio\",\n","    \"ca\": \"num_venas_grandes\", \"thal\": \"estado_corazon_thal\"\n","}\n","cols_a_clippear = ['tension_en_descanso', 'colesterol', 'latidos_por_minuto', 'cambio_linea_corazon_ejercicio']\n","categorical_cols_to_round = ['num_venas_grandes', 'estado_corazon_thal', 'sexo', 'tipo_dolor_pecho',\n","                             'dolor_pecho_con_ejercicio', 'azucar', 'forma_linea_corazon_ejercicio', 'electro_en_descanso']\n","\n","def limpieza_inicial(df):\n","    df = df.copy()\n","    for col in df.columns:\n","        if col != 'label':\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","    for col in cols_to_int:\n","        if col in df.columns:\n","            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n","    df = df.rename(columns=rename_dict)\n","    df.replace([-9, -9.0], np.nan, inplace=True)\n","    return df\n","\n","def limpiar_ceros_fisiologicos(X):\n","    X = X.copy()\n","    for col in ['tension_en_descanso', 'colesterol']:\n","        if col in X.columns:\n","            X[col] = X[col].replace({0: np.nan, 0.0: np.nan})\n","    return X\n","\n","def clipear_outliers(X):\n","    X = X.copy()\n","    for col in cols_a_clippear:\n","        if col in X.columns:\n","            p1 = X[col].quantile(0.01)\n","            p99 = X[col].quantile(0.99)\n","            X[col] = X[col].clip(lower=p1, upper=p99)\n","    return X\n","\n","def crear_flags_mnar(df):\n","    df_new = df.copy()\n","    cols_mnar = ['num_venas_grandes']\n","    for col in cols_mnar:\n","        if col in df_new.columns:\n","            df_new[f'{col}_is_missing'] = df_new[col].isna().astype(int)\n","    return df_new\n","\n","def redondear_imputaciones(X):\n","    X = X.copy()\n","    for col in categorical_cols_to_round:\n","        if col in X.columns:\n","            X[col] = X[col].round()\n","    return X\n","\n","def aplicar_feature_engineering_avanzado(df):\n","    df = df.copy()\n","    if 'cambio_linea_corazon_ejercicio' in df.columns:\n","        df['flag_depresion_st'] = (df['cambio_linea_corazon_ejercicio'] > 0).astype(int)\n","    if 'tension_en_descanso' in df.columns:\n","        df['flag_hipertension'] = (df['tension_en_descanso'] > 130).astype(int)\n","    if 'dolor_pecho_con_ejercicio' in df.columns and 'flag_depresion_st' in df.columns:\n","        df['score_respuesta_stress'] = df['dolor_pecho_con_ejercicio'] + df['flag_depresion_st']\n","    cols_comorbilidad = ['azucar', 'flag_hipertension', 'electro_en_descanso']\n","    if set(cols_comorbilidad).issubset(df.columns):\n","        electro_punto = (df['electro_en_descanso'] > 0).astype(int)\n","        df['carga_comorbilidad'] = df['azucar'] + df['flag_hipertension'] + electro_punto\n","    return df\n","\n","def ejecutar_pruning_agresivo(df):\n","    df = df.copy()\n","    vars_a_eliminar = ['electro_en_descanso', 'colesterol', 'azucar', 'tension_en_descanso']\n","    cols_existentes = [c for c in vars_a_eliminar if c in df.columns]\n","    if cols_existentes:\n","        df = df.drop(columns=cols_existentes)\n","    return df\n","\n","class RobustKNNImputerWrapper(BaseEstimator, TransformerMixin):\n","    def __init__(self, n_neighbors=5):\n","        self.n_neighbors = n_neighbors\n","        self.scaler = RobustScaler()\n","        self.imputer = KNNImputer(n_neighbors=n_neighbors, weights='distance')\n","        self.feature_names_in_ = None\n","    def fit(self, X, y=None):\n","        self.feature_names_in_ = X.columns if hasattr(X, 'columns') else [f\"feat_{i}\" for i in range(X.shape[1])]\n","        X_scaled = self.scaler.fit_transform(X)\n","        self.imputer.fit(X_scaled)\n","        return self\n","    def transform(self, X):\n","        X_scaled = self.scaler.transform(X)\n","        X_imputed_scaled = self.imputer.transform(X_scaled)\n","        X_imputed = self.scaler.inverse_transform(X_imputed_scaled)\n","        return pd.DataFrame(X_imputed, columns=self.feature_names_in_, index=X.index)\n","\n","# =============================================================================\n","# 2. CONSTRUCCI√ìN DE PIPELINES ESPEC√çFICOS\n","# =============================================================================\n","\n","# PIPELINE A: EL DEL SVM (Complejo + Pruning) - Esto replica tu √©xito de 0.565\n","prep_svm = Pipeline([\n","    ('limpieza_ceros', FunctionTransformer(limpiar_ceros_fisiologicos, validate=False)),\n","    ('clipear_outliers', FunctionTransformer(clipear_outliers, validate=False)),\n","    ('mnar_flags', FunctionTransformer(crear_flags_mnar, validate=False)),\n","    ('imputacion_robusta', RobustKNNImputerWrapper(n_neighbors=5)), # K=5 por defecto\n","    ('rounding', FunctionTransformer(redondear_imputaciones, validate=False)),\n","    ('feature_engineering', FunctionTransformer(aplicar_feature_engineering_avanzado, validate=False)),\n","    ('pruning_agresivo', FunctionTransformer(ejecutar_pruning_agresivo, validate=False)),\n","    ('final_scaler', RobustScaler())\n","])\n","\n","# PIPELINE B: EL DE LOS √ÅRBOLES (Simple + Datos Sucios) - Esto replica tu √©xito de 0.57\n","prep_trees = Pipeline([\n","    ('limpieza_ceros', FunctionTransformer(limpiar_ceros_fisiologicos, validate=False)),\n","    ('clipear', FunctionTransformer(clipear_outliers, validate=False)),\n","    ('imputer', SimpleImputer(strategy='median'))\n","    # SIN PRUNING, SIN SCALER, SIN FE COMPLEJO\n","])\n","\n","# =============================================================================\n","# 3. CARGA Y PREPARACI√ìN INICIAL\n","# =============================================================================\n","# Cargar datos\n","# df = pd.read_csv('/content/drive/MyDrive/Cupido_IA_project/train.csv')\n","# df_test = pd.read_csv('/content/drive/MyDrive/Cupido_IA_project/test.csv')\n","\n","# Limpieza de tipos b√°sica\n","df_clean = limpieza_inicial(df)\n","df_test_clean = limpieza_inicial(df_test)\n","\n","X = df_clean.drop('label', axis=1)\n","y = df_clean['label']\n","\n","X_test_final = df_test_clean.copy()\n","if 'label' in X_test_final.columns:\n","    X_test_final = X_test_final.drop('label', axis=1)\n","\n","print(\"‚úÖ Datos base cargados. Iniciando entrenamiento de Stacking Paralelo...\")\n","\n","# =============================================================================\n","# 4. DEFINICI√ìN DEL STACKING CON PIPELINES INTEGRADOS\n","# =============================================================================\n","\n","# Envolvemos cada modelo con SU pipeline de preprocesado correspondiente\n","\n","# Grupo √Årboles (Usan prep_trees)\n","rf_pipe = Pipeline([('prep', prep_trees), ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=5, class_weight='balanced', random_state=42))])\n","xgb_pipe = Pipeline([('prep', prep_trees), ('xgb', XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=1.0, use_label_encoder=False, eval_metric='mlogloss', random_state=42))])\n","brf_pipe = Pipeline([('prep', prep_trees), ('brf', BalancedRandomForestClassifier(n_estimators=200, min_samples_split=2, random_state=42))])\n","eec_pipe = Pipeline([('prep', prep_trees), ('eec', EasyEnsembleClassifier(n_estimators=10, sampling_strategy='auto', random_state=42))])\n","\n","# Grupo SVM (Usa prep_svm) - AQU√ç EST√Å LA MAGIA\n","svm_pipe_full = Pipeline([\n","    ('prep', prep_svm),\n","    ('svm', SVC(C=1, gamma=0.05, kernel='rbf', probability=True, random_state=42))\n","])\n","\n","# Grupo LR (Usa prep_svm tambi√©n, le viene bien el escalado y limpieza)\n","lr_pipe_full = Pipeline([\n","    ('prep', prep_svm),\n","    ('lr', LogisticRegression(C=1, penalty='l2', solver='lbfgs', max_iter=1000, random_state=42))\n","])\n","\n","print(\"üöÄ Entrenando Stacking Final...\")\n","\n","stacking_clf_final = StackingClassifier(\n","    estimators=[\n","        ('lr', lr_pipe_full),   # Recibe datos limpios\n","        ('rf', rf_pipe),        # Recibe datos sucios\n","        ('xgb', xgb_pipe),      # Recibe datos sucios\n","        ('brf', brf_pipe),      # Recibe datos sucios\n","        ('eec', eec_pipe),      # Recibe datos sucios\n","        ('svm', svm_pipe_full)  # Recibe datos limpios (PRUNED)\n","    ],\n","    final_estimator=LogisticRegression(max_iter=1000, class_weight='balanced'),\n","    cv=5,\n","    n_jobs=-1\n",")\n","\n","stacking_clf_final.fit(X, y)\n","print(\"‚úÖ Entrenamiento completado.\")\n","\n","# =============================================================================\n","# 5. GENERAR SUBMISSION\n","# =============================================================================\n","print(\"Generando submission...\")\n","y_pred_final = stacking_clf_final.predict(X_test_final)\n","\n","submission_ids = df_test.index if 'ID' not in df_test.columns else df_test['ID']\n","sub = pd.DataFrame({\n","    \"ID\": submission_ids,\n","    \"label\": y_pred_final.astype(int)\n","})\n","\n","filename = \"submission_Stacking_Parallel_Pipelines.csv\"\n","sub.to_csv(filename, index=False)\n","\n","print(f\"üèÜ ¬°Archivo '{filename}' guardado!\")\n","print(\"   Estrategia: Cada modelo recibe sus datos ideales (SVM->Pruned, √Årboles->Raw)\")\n","print(sub.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAn3pbApBJej","executionInfo":{"status":"ok","timestamp":1764946676074,"user_tz":-60,"elapsed":22619,"user":{"displayName":"Yannis German Saura","userId":"11705243329343073633"}},"outputId":"935985e9-ad5b-4d2e-dcd6-2304e6770afc"},"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ö° ENTRENANDO STACKING AVANZADO: PIPELINES PARALELOS (SVM Pruned + √Årboles Raw) ‚ö°\n","‚úÖ Datos base cargados. Iniciando entrenamiento de Stacking Paralelo...\n","üöÄ Entrenando Stacking Final...\n","‚úÖ Entrenamiento completado.\n","Generando submission...\n","üèÜ ¬°Archivo 'submission_Stacking_Parallel_Pipelines.csv' guardado!\n","   Estrategia: Cada modelo recibe sus datos ideales (SVM->Pruned, √Årboles->Raw)\n","   ID  label\n","0   0      4\n","1   1      0\n","2   2      0\n","3   3      4\n","4   4      0\n"]}]},{"cell_type":"markdown","source":["---\n","\n","## DOCUMENTACI√ìN\n","\n","---"],"metadata":{"id":"sCh87QJ5E_eC"}},{"cell_type":"markdown","source":["El objetivo de esta fase fue intentar batir el r√©cord interno del equipo (**0.57**, logrado por un *Stacking Random Classifier* en una l√≠nea paralela) mediante el uso de arquitecturas avanzadas y un preprocesado quir√∫rgico.\n","\n","### 1. ü§ñ Estrategia de Modelado: El Foco en √Årboles\n","La mayor√≠a de los ensambles de esta iteraci√≥n se construyeron priorizando modelos de **√°rboles no lineales** (Random Forest, XGBoost, CatBoost).\n","* **Racional:** Se eligi√≥ este enfoque porque fue precisamente esta familia de algoritmos la que logr√≥ el r√©cord de **0.57** utilizando un preprocesado simple. Se intent√≥ replicar ese √©xito combin√°ndolos con nuevas t√©cnicas de limpieza.\n","\n","### 2. üß™ Resultados y Eficiencia (El Retorno del SVM)\n","A pesar de la complejidad de los ensambles probados, el an√°lisis de resultados revela un hallazgo sobre la eficiencia:\n","* **Mejor Retorno por Complejidad:** El **SVM Individual (Optimizado + Pruned)** logr√≥ un score de **0.565**, empatando t√©cnicamente con los ensambles jer√°rquicos m√°s complejos de esta fase.\n","* **Techo de la Iteraci√≥n:** Ninguna de las arquitecturas propuestas (Stacking H√≠brido, Pipelines Paralelos) logr√≥ superar el **0.57** del *Stacking Random Classifier* de referencia. La complejidad a√±adida en esta fase no aport√≥ valor incremental sobre el modelo base bien preprocesado.\n","\n","### 3. üìâ Conclusi√≥n T√©cnica\n","Se ha demostrado que, bajo el esquema de preprocesado avanzado (\"Pruning\"), un modelo geom√©trico simple (SVM) es capaz de igualar a ensambles masivos. Sin embargo, para romper la barrera del 0.57, la sofisticaci√≥n del modelo no es suficiente; el l√≠mite parece estar en la estructura actual de los datos.\n","\n","---\n","\n","### üìù P.D. An√°lisis Competitivo (El salto al 0.60)\n","Se observa que equipos rivales han alcanzado puntuaciones de **0.59 - 0.60**.\n","* **Diagn√≥stico:** Dado que nuestros modelos (tanto lineales como no lineales) se han estancado en el rango 0.54-0.57 independientemente de la arquitectura, es altamente probable que la ventaja de los rivales no provenga del modelo, sino de la **informaci√≥n**.\n","* **Hip√≥tesis:** Es posible que hayan logrado desbloquear la \"Clase 2\" (el punto ciego de nuestros modelos) mediante:\n","    1.  **Ingenier√≠a de Caracter√≠sticas de Dominio:** Creaci√≥n de variables no lineales muy espec√≠ficas que nosotros hemos eliminado en el *pruning*.\n","    3.  **Preprocesado Diferencial:** Una imputaci√≥n que preserve mejor la varianza de los grados intermedios de enfermedad que nuestro enfoque robusto."],"metadata":{"id":"qkGAcPSuFQzz"}}]}